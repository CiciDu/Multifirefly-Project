{
    "policy_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVMAAAAAAAAACMHnN0YWJsZV9iYXNlbGluZXMzLnNhYy5wb2xpY2llc5SMCVNBQ1BvbGljeZSTlC4=",
        "__module__": "stable_baselines3.sac.policies",
        "__doc__": "\n    Policy class (with both actor and critic) for SAC.\n\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not\n    :param log_std_init: Initial value for the log standard deviation\n    :param sde_net_arch: Network architecture for extracting features\n        when using gSDE. If None, the latent features from the policy will be used.\n        Pass an empty list to use the states as features.\n    :param use_expln: Use ``expln()`` function instead of ``exp()`` when using gSDE to ensure\n        a positive standard deviation (cf paper). It allows to keep variance\n        above zero and prevent it from growing too fast. In practice, ``exp()`` is usually enough.\n    :param clip_mean: Clip the mean output when using gSDE to avoid numerical instability.\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments\n        to pass to the features extractor.\n    :param normalize_images: Whether to normalize images or not,\n         dividing by 255.0 (True by default)\n    :param optimizer_class: The optimizer to use,\n        ``th.optim.Adam`` by default\n    :param optimizer_kwargs: Additional keyword arguments,\n        excluding the learning rate, to pass to the optimizer\n    :param n_critics: Number of critic networks to create.\n    :param share_features_extractor: Whether to share or not the features extractor\n        between the actor and the critic (this saves computation time)\n    ",
        "__init__": "<function SACPolicy.__init__ at 0x7fc4b3d38ca0>",
        "_build": "<function SACPolicy._build at 0x7fc4b3d38d30>",
        "_get_constructor_parameters": "<function SACPolicy._get_constructor_parameters at 0x7fc4b3d38dc0>",
        "reset_noise": "<function SACPolicy.reset_noise at 0x7fc4b3d38e50>",
        "make_actor": "<function SACPolicy.make_actor at 0x7fc4b3d38ee0>",
        "make_critic": "<function SACPolicy.make_critic at 0x7fc4b3d38f70>",
        "forward": "<function SACPolicy.forward at 0x7fc4b3d42040>",
        "_predict": "<function SACPolicy._predict at 0x7fc4b3d420d0>",
        "set_training_mode": "<function SACPolicy.set_training_mode at 0x7fc4b3d42160>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x7fc4b3d41280>"
    },
    "verbose": false,
    "policy_kwargs": {
        ":type:": "<class 'dict'>",
        ":serialized:": "gAWVWgAAAAAAAAB9lCiMDWFjdGl2YXRpb25fZm6UjBt0b3JjaC5ubi5tb2R1bGVzLmFjdGl2YXRpb26UjARSZUxVlJOUjAhuZXRfYXJjaJRdlChLQEtAZYwHdXNlX3NkZZSJdS4=",
        "activation_fn": "<class 'torch.nn.modules.activation.ReLU'>",
        "net_arch": [
            64,
            64
        ],
        "use_sde": false
    },
    "observation_space": {
        ":type:": "<class 'gym.spaces.box.Box'>",
        ":serialized:": "gAWVnwEAAAAAAACMDmd5bS5zcGFjZXMuYm94lIwDQm94lJOUKYGUfZQojAVkdHlwZZSMBW51bXB5lGgFk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGKMBl9zaGFwZZRLCIWUjANsb3eUjBJudW1weS5jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWIAAAAAAAAAAAAIC/AACAvwAAgL8AAIC/AACAvwAAgL8AAIC/AACAv5RoCksIhZSMAUOUdJRSlIwEaGlnaJRoEiiWIAAAAAAAAAAAAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/AACAP5RoCksIhZRoFXSUUpSMDWJvdW5kZWRfYmVsb3eUaBIolggAAAAAAAAAAQEBAQEBAQGUaAeMAmIxlImIh5RSlChLA4wBfJROTk5K/////0r/////SwB0lGJLCIWUaBV0lFKUjA1ib3VuZGVkX2Fib3ZllGgSKJYIAAAAAAAAAAEBAQEBAQEBlGghSwiFlGgVdJRSlIwKX25wX3JhbmRvbZROdWIu",
        "dtype": "float32",
        "_shape": [
            8
        ],
        "low": "[-1. -1. -1. -1. -1. -1. -1. -1.]",
        "high": "[1. 1. 1. 1. 1. 1. 1. 1.]",
        "bounded_below": "[ True  True  True  True  True  True  True  True]",
        "bounded_above": "[ True  True  True  True  True  True  True  True]",
        "_np_random": null
    },
    "action_space": {
        ":type:": "<class 'gym.spaces.box.Box'>",
        ":serialized:": "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",
        "dtype": "float32",
        "_shape": [
            2
        ],
        "low": "[-1. -1.]",
        "high": "[1. 1.]",
        "bounded_below": "[ True  True]",
        "bounded_above": "[ True  True]",
        "_np_random": "RandomState(MT19937)"
    },
    "n_envs": 1,
    "num_timesteps": 20000,
    "_total_timesteps": 50000000,
    "_num_timesteps_at_start": 0,
    "seed": null,
    "action_noise": null,
    "start_time": 1661229646.325664,
    "learning_rate": 0.01,
    "tensorboard_log": null,
    "lr_schedule": {
        ":type:": "<class 'function'>",
        ":serialized:": "gAWVCwMAAAAAAACMF2Nsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwFLAEsASwFLAUsTQwSIAFMAlE6FlCmMAV+UhZSMbC9Vc2Vycy9kdXNpeWkvLmNvbmRhL2VudnMvTXVsdGlmaXJlZmx5LVByb2plY3QvbGliL3B5dGhvbjMuOS9zaXRlLXBhY2thZ2VzL3N0YWJsZV9iYXNlbGluZXMzL2NvbW1vbi91dGlscy5weZSMBGZ1bmOUS4BDAgABlIwDdmFslIWUKXSUUpR9lCiMC19fcGFja2FnZV9flIwYc3RhYmxlX2Jhc2VsaW5lczMuY29tbW9ulIwIX19uYW1lX1+UjB5zdGFibGVfYmFzZWxpbmVzMy5jb21tb24udXRpbHOUjAhfX2ZpbGVfX5SMbC9Vc2Vycy9kdXNpeWkvLmNvbmRhL2VudnMvTXVsdGlmaXJlZmx5LVByb2plY3QvbGliL3B5dGhvbjMuOS9zaXRlLXBhY2thZ2VzL3N0YWJsZV9iYXNlbGluZXMzL2NvbW1vbi91dGlscy5weZR1Tk5oAIwQX21ha2VfZW1wdHlfY2VsbJSTlClSlIWUdJRSlIwcY2xvdWRwaWNrbGUuY2xvdWRwaWNrbGVfZmFzdJSMEl9mdW5jdGlvbl9zZXRzdGF0ZZSTlGgffZR9lChoFmgNjAxfX3F1YWxuYW1lX1+UjBljb25zdGFudF9mbi48bG9jYWxzPi5mdW5jlIwPX19hbm5vdGF0aW9uc19flH2UjA5fX2t3ZGVmYXVsdHNfX5ROjAxfX2RlZmF1bHRzX1+UTowKX19tb2R1bGVfX5RoF4wHX19kb2NfX5ROjAtfX2Nsb3N1cmVfX5RoAIwKX21ha2VfY2VsbJSTlEc/hHrhR64Ue4WUUpSFlIwXX2Nsb3VkcGlja2xlX3N1Ym1vZHVsZXOUXZSMC19fZ2xvYmFsc19flH2UdYaUhlIwLg=="
    },
    "_last_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVlQAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYgAAAAAAAAADDmEr7HW4S9w7yeQwAAAEAAAAAAAAAAAAAAyEMAAAAAlIwFbnVtcHmUjAVkdHlwZZSTlIwCZjSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYksBSwiGlIwBQ5R0lFKULg=="
    },
    "_last_episode_starts": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVdAAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYBAAAAAAAAAAGUjAVudW1weZSMBWR0eXBllJOUjAJiMZSJiIeUUpQoSwOMAXyUTk5OSv////9K/////0sAdJRiSwGFlIwBQ5R0lFKULg=="
    },
    "_last_original_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVlQAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYgAAAAAAAAALxBk70AAACA+BemQwAAQEAAAAAAAAAAAAAAyEMAAAAAlIwFbnVtcHmUjAVkdHlwZZSTlIwCZjSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYksBSwiGlIwBQ5R0lFKULg=="
    },
    "_episode_num": 1,
    "use_sde": false,
    "sde_sample_freq": -1,
    "_current_progress_remaining": 0.99960002,
    "ep_info_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVQAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKUfZQojAFylE08c4wBbJRNgD6MAXSUR0A4iLytmthedWEu"
    },
    "ep_success_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVIAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKULg=="
    },
    "_n_updates": 199,
    "buffer_size": 1000000,
    "batch_size": 1024,
    "learning_starts": 10,
    "tau": 0.005,
    "gamma": 0.9999,
    "gradient_steps": 1,
    "optimize_memory_usage": false,
    "replay_buffer_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVNQAAAAAAAACMIHN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi5idWZmZXJzlIwMUmVwbGF5QnVmZmVylJOULg==",
        "__module__": "stable_baselines3.common.buffers",
        "__doc__": "\n    Replay buffer used in off-policy algorithms like SAC/TD3.\n\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device:\n    :param n_envs: Number of parallel environments\n    :param optimize_memory_usage: Enable a memory efficient variant\n        of the replay buffer which reduces by almost a factor two the memory used,\n        at a cost of more complexity.\n        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n        and https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n        Cannot be used in combination with handle_timeout_termination.\n    :param handle_timeout_termination: Handle timeout termination (due to timelimit)\n        separately and treat the task as infinite horizon task.\n        https://github.com/DLR-RM/stable-baselines3/issues/284\n    ",
        "__init__": "<function ReplayBuffer.__init__ at 0x7fc4a0919c10>",
        "add": "<function ReplayBuffer.add at 0x7fc4a0919ca0>",
        "sample": "<function ReplayBuffer.sample at 0x7fc4a0919d30>",
        "_get_samples": "<function ReplayBuffer._get_samples at 0x7fc4a0919dc0>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x7fc4a09216c0>"
    },
    "replay_buffer_kwargs": {},
    "train_freq": {
        ":type:": "<class 'stable_baselines3.common.type_aliases.TrainFreq'>",
        ":serialized:": "gAWVYQAAAAAAAACMJXN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi50eXBlX2FsaWFzZXOUjAlUcmFpbkZyZXGUk5RLZGgAjBJUcmFpbkZyZXF1ZW5jeVVuaXSUk5SMBHN0ZXCUhZRSlIaUgZQu"
    },
    "use_sde_at_warmup": false,
    "target_entropy": {
        ":type:": "<class 'numpy.float32'>",
        ":serialized:": "gAWVZQAAAAAAAACMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMBnNjYWxhcpSTlIwFbnVtcHmUjAVkdHlwZZSTlIwCZjSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYkMEAAAAwJSGlFKULg=="
    },
    "ent_coef": "auto",
    "target_update_interval": 20
}